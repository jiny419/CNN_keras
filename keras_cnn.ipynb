{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Sound Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15166277912288398436\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7663451028479636953\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13276675287482182307\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10619178189\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 4\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 5\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 6\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 7\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 15986381524773473011\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:1a:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10913166132\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 4\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 5\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 6\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 7\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 10885908281284313170\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:1b:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10913166132\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 4\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 5\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 6\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 7\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 11923250831100533215\n",
      "physical_device_desc: \"device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:60:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:3\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10913166132\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 4\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 5\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 6\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 7\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 10301678609335312738\n",
      "physical_device_desc: \"device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:61:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:4\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10913166132\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 5\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 6\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 7\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 14274699674059168339\n",
      "physical_device_desc: \"device: 4, name: GeForce GTX 1080 Ti, pci bus id: 0000:b1:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:5\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10913166132\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 4\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 6\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 7\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 4090124701547614121\n",
      "physical_device_desc: \"device: 5, name: GeForce GTX 1080 Ti, pci bus id: 0000:b2:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:6\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10913166132\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 4\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 5\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 7\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 2295910443526486446\n",
      "physical_device_desc: \"device: 6, name: GeForce GTX 1080 Ti, pci bus id: 0000:da:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:7\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10913166132\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 4\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 5\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 6\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 14944565840436645992\n",
      "physical_device_desc: \"device: 7, name: GeForce GTX 1080 Ti, pci bus id: 0000:db:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()) #gpu 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical \n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, AveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_files = np.load('./urban8K_STFT_All-002.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X', 'y', 'fn_s']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_files.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = npz_files['X']\n",
    "y = npz_files['y']\n",
    "fn_s = npz_files['fn_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7333, 89010), (7333,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, 'Data/UrbanSound8K/audio/fold10/159742-8-0-2.wav')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0], fn_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(len(X))\n",
    "X = X[shuffle_index]\n",
    "y = y[shuffle_index]\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5866, 89010), (5866, 10), (1467, 89010), (1467, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],129,690,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],129,690,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5866, 129, 690, 1), (1467, 129, 690, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sequential()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape) :\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=(5,5), strides=(1,1), padding='same',\n",
    "                         activation='relu', input_shape=input_shape))\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(4,8), strides=(4,8)))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(5,5), strides=(1,1), padding='same',\n",
    "                         activation='relu'))\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(4,8), strides=(4,8)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 129, 690, 32)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 86, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 10, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2621952   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,679,178\n",
      "Trainable params: 2,679,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_size = (129,690,1)\n",
    "model = CNN(image_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5279 samples, validate on 587 samples\n",
      "Epoch 1/20\n",
      "5279/5279 [==============================] - 14s 3ms/step - loss: 1.7477 - acc: 0.3950 - val_loss: 1.3046 - val_acc: 0.5315\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.30461, saving model to ./model/urban_sound1.h5\n",
      "Epoch 2/20\n",
      "5279/5279 [==============================] - 10s 2ms/step - loss: 1.2280 - acc: 0.5829 - val_loss: 1.0451 - val_acc: 0.6320\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.30461 to 1.04511, saving model to ./model/urban_sound1.h5\n",
      "Epoch 3/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 1.0162 - acc: 0.6492 - val_loss: 0.9872 - val_acc: 0.6542\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.04511 to 0.98725, saving model to ./model/urban_sound1.h5\n",
      "Epoch 4/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.8575 - acc: 0.7088 - val_loss: 0.8431 - val_acc: 0.7394\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.98725 to 0.84311, saving model to ./model/urban_sound1.h5\n",
      "Epoch 5/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.7397 - acc: 0.7511 - val_loss: 0.7980 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.84311 to 0.79799, saving model to ./model/urban_sound1.h5\n",
      "Epoch 6/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.6907 - acc: 0.7736 - val_loss: 0.7834 - val_acc: 0.7359\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.79799 to 0.78341, saving model to ./model/urban_sound1.h5\n",
      "Epoch 7/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.5874 - acc: 0.7996 - val_loss: 0.8070 - val_acc: 0.7376\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.78341\n",
      "Epoch 8/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.4974 - acc: 0.8291 - val_loss: 0.8063 - val_acc: 0.7785\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.78341\n",
      "Epoch 9/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.4642 - acc: 0.8485 - val_loss: 0.6358 - val_acc: 0.8211\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.78341 to 0.63581, saving model to ./model/urban_sound1.h5\n",
      "Epoch 10/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.4010 - acc: 0.8625 - val_loss: 0.6399 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.63581\n",
      "Epoch 11/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.3633 - acc: 0.8795 - val_loss: 0.7268 - val_acc: 0.7990\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.63581\n",
      "Epoch 12/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.3754 - acc: 0.8767 - val_loss: 0.6228 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.63581 to 0.62281, saving model to ./model/urban_sound1.h5\n",
      "Epoch 13/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.3217 - acc: 0.8996 - val_loss: 0.5642 - val_acc: 0.8416\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.62281 to 0.56423, saving model to ./model/urban_sound1.h5\n",
      "Epoch 14/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.3093 - acc: 0.8992 - val_loss: 0.5628 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.56423 to 0.56285, saving model to ./model/urban_sound1.h5\n",
      "Epoch 15/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.2570 - acc: 0.9146 - val_loss: 0.5142 - val_acc: 0.8569\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.56285 to 0.51421, saving model to ./model/urban_sound1.h5\n",
      "Epoch 16/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.2119 - acc: 0.9348 - val_loss: 0.5572 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.51421\n",
      "Epoch 17/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.2109 - acc: 0.9348 - val_loss: 0.5885 - val_acc: 0.8552\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.51421\n",
      "Epoch 18/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.2125 - acc: 0.9341 - val_loss: 0.6393 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.51421\n",
      "Epoch 19/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.1975 - acc: 0.9394 - val_loss: 0.6872 - val_acc: 0.8399\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.51421\n",
      "Epoch 20/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.2173 - acc: 0.9305 - val_loss: 0.5791 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.51421\n",
      "Epoch 00020: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbee8213208>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat = 5 \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "\n",
    "\n",
    "MODEL_SAVE_FOLDER_PATH = './model/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + 'urban_sound1.h5'\n",
    "model_checkpoint = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "input_shape = (129,690,1)\n",
    "model = CNN(input_shape)\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping, model_checkpoint], \n",
    "              verbose=1, validation_split=0.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467/1467 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.555438765434481, 0.8568507162746152]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model/urban_sound1.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CNN2(input_shape) :\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "                             activation='relu', input_shape=input_shape))\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "                             activation='relu'))\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(3,3), strides=(3,3), padding='valid'))\n",
    "\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "                             activation='relu'))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(3,5), strides=(2,3), padding='same',\n",
    "                             activation='relu'))\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(3,3), strides=(3,3), padding='same'))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(10,3), strides=(3,3), padding='same',\n",
    "                             activation='relu'))\n",
    "\n",
    "        model.add(AveragePooling2D(pool_size=(3,3), strides=(2,3), padding='same'))\n",
    "\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "                             activation='relu'))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "        return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 129, 690, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 129, 690, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 43, 230, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 43, 230, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 43, 230, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 22, 77, 64)        61504     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 26, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 9, 64)          122944    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 2, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              787456    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,084,074\n",
      "Trainable params: 1,084,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (129,690,1)\n",
    "model = CNN2(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5279 samples, validate on 587 samples\n",
      "Epoch 1/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 1.8889 - acc: 0.3082 - val_loss: 1.5573 - val_acc: 0.4617\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.55726, saving model to ./model/urban_sound2.h5\n",
      "Epoch 2/20\n",
      "5279/5279 [==============================] - 19s 4ms/step - loss: 1.3863 - acc: 0.5007 - val_loss: 1.1930 - val_acc: 0.5520\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.55726 to 1.19297, saving model to ./model/urban_sound2.h5\n",
      "Epoch 3/20\n",
      "5279/5279 [==============================] - 20s 4ms/step - loss: 1.1130 - acc: 0.6206 - val_loss: 1.0001 - val_acc: 0.6235\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.19297 to 1.00009, saving model to ./model/urban_sound2.h5\n",
      "Epoch 4/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.9162 - acc: 0.6818 - val_loss: 0.9024 - val_acc: 0.6610\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.00009 to 0.90244, saving model to ./model/urban_sound2.h5\n",
      "Epoch 5/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.7625 - acc: 0.7471 - val_loss: 0.7020 - val_acc: 0.7666\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.90244 to 0.70198, saving model to ./model/urban_sound2.h5\n",
      "Epoch 6/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.6263 - acc: 0.7892 - val_loss: 0.6215 - val_acc: 0.7785\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.70198 to 0.62146, saving model to ./model/urban_sound2.h5\n",
      "Epoch 7/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.5071 - acc: 0.8322 - val_loss: 0.5109 - val_acc: 0.8296\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62146 to 0.51086, saving model to ./model/urban_sound2.h5\n",
      "Epoch 8/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.4135 - acc: 0.8581 - val_loss: 0.5737 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.51086\n",
      "Epoch 9/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.4021 - acc: 0.8621 - val_loss: 0.4721 - val_acc: 0.8416\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51086 to 0.47205, saving model to ./model/urban_sound2.h5\n",
      "Epoch 10/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.3175 - acc: 0.8934 - val_loss: 0.4212 - val_acc: 0.8535\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.47205 to 0.42115, saving model to ./model/urban_sound2.h5\n",
      "Epoch 11/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.2732 - acc: 0.9070 - val_loss: 0.4029 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.42115 to 0.40286, saving model to ./model/urban_sound2.h5\n",
      "Epoch 12/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.2607 - acc: 0.9102 - val_loss: 0.4015 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.40286 to 0.40146, saving model to ./model/urban_sound2.h5\n",
      "Epoch 13/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.2421 - acc: 0.9193 - val_loss: 0.4438 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.40146\n",
      "Epoch 14/20\n",
      "5279/5279 [==============================] - 22s 4ms/step - loss: 0.2694 - acc: 0.9125 - val_loss: 0.4333 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.40146\n",
      "Epoch 15/20\n",
      "5279/5279 [==============================] - 22s 4ms/step - loss: 0.2149 - acc: 0.9246 - val_loss: 0.3658 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.40146 to 0.36577, saving model to ./model/urban_sound2.h5\n",
      "Epoch 16/20\n",
      "5279/5279 [==============================] - 22s 4ms/step - loss: 0.1817 - acc: 0.9377 - val_loss: 0.3632 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.36577 to 0.36320, saving model to ./model/urban_sound2.h5\n",
      "Epoch 17/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.1895 - acc: 0.9358 - val_loss: 0.3315 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.36320 to 0.33153, saving model to ./model/urban_sound2.h5\n",
      "Epoch 18/20\n",
      "5279/5279 [==============================] - 22s 4ms/step - loss: 0.1413 - acc: 0.9532 - val_loss: 0.2749 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33153 to 0.27490, saving model to ./model/urban_sound2.h5\n",
      "Epoch 19/20\n",
      "5279/5279 [==============================] - 21s 4ms/step - loss: 0.1027 - acc: 0.9648 - val_loss: 0.2902 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.27490\n",
      "Epoch 20/20\n",
      "5279/5279 [==============================] - 22s 4ms/step - loss: 0.1131 - acc: 0.9606 - val_loss: 0.2922 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.27490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbee8213128>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "\n",
    "MODEL_SAVE_FOLDER_PATH = './model/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + 'urban_sound2.h5'\n",
    "model_checkpoint = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping, model_checkpoint], verbose=1, validation_split=0.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467/1467 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3525529625205337, 0.9154737556801414]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model/urban_sound2.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**functional**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 129, 690, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 129, 690, 32)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 32, 86, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 10, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               2621952   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,679,178\n",
      "Trainable params: 2,679,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Concatenate\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "\n",
    "visible = Input(shape=(129,690,1))\n",
    "\n",
    "conv1 = Conv2D(32, kernel_size=(5, 5), strides=(1,1), activation='relu', padding='same')(visible)\n",
    "\n",
    "pool1 = MaxPooling2D(pool_size=(4, 8), strides=(4,8))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, kernel_size=(5, 5), strides=(1,1), activation='relu', padding='same')(pool1)\n",
    "\n",
    "pool2 = MaxPooling2D(pool_size=(4, 8), strides=(4,8))(conv2)\n",
    "\n",
    "flat = Flatten()(pool2)\n",
    "\n",
    "hidden1 = Dense(512, activation='relu')(flat)\n",
    "\n",
    "output = Dense(10, activation='softmax')(hidden1)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# plot graph\n",
    "# plot_model(model, to_file='convolutional_neural_network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5279 samples, validate on 587 samples\n",
      "Epoch 1/20\n",
      "5279/5279 [==============================] - 12s 2ms/step - loss: 1.6368 - acc: 0.4467 - val_loss: 1.2269 - val_acc: 0.5656\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.22692, saving model to ./model/urban_sound1_functional.h5\n",
      "Epoch 2/20\n",
      "5279/5279 [==============================] - 12s 2ms/step - loss: 1.0782 - acc: 0.6437 - val_loss: 0.9710 - val_acc: 0.6951\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.22692 to 0.97095, saving model to ./model/urban_sound1_functional.h5\n",
      "Epoch 3/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.8206 - acc: 0.7384 - val_loss: 0.8751 - val_acc: 0.7342\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.97095 to 0.87510, saving model to ./model/urban_sound1_functional.h5\n",
      "Epoch 4/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.6368 - acc: 0.7979 - val_loss: 0.7620 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.87510 to 0.76201, saving model to ./model/urban_sound1_functional.h5\n",
      "Epoch 5/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.5667 - acc: 0.8138 - val_loss: 0.8568 - val_acc: 0.7632\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.76201\n",
      "Epoch 6/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.4642 - acc: 0.8464 - val_loss: 0.6942 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.76201 to 0.69422, saving model to ./model/urban_sound1_functional.h5\n",
      "Epoch 7/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.3657 - acc: 0.8863 - val_loss: 0.7071 - val_acc: 0.8143\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.69422\n",
      "Epoch 8/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.3146 - acc: 0.9017 - val_loss: 0.6506 - val_acc: 0.8211\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.69422 to 0.65059, saving model to ./model/urban_sound1_functional.h5\n",
      "Epoch 9/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.2427 - acc: 0.9256 - val_loss: 0.6961 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.65059\n",
      "Epoch 10/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.1945 - acc: 0.9362 - val_loss: 0.7373 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.65059\n",
      "Epoch 11/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.3282 - acc: 0.9055 - val_loss: 0.8216 - val_acc: 0.8075\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.65059\n",
      "Epoch 12/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.2222 - acc: 0.9333 - val_loss: 0.6948 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.65059\n",
      "Epoch 13/20\n",
      "5279/5279 [==============================] - 11s 2ms/step - loss: 0.1821 - acc: 0.9443 - val_loss: 0.6827 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.65059\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbebc161400>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "\n",
    "MODEL_SAVE_FOLDER_PATH = './model/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + 'urban_sound1_functional.h5'\n",
    "model_checkpoint = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping, model_checkpoint], verbose=1, validation_split=0.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467/1467 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7074067416082211, 0.8145875942568919]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model/urban_sound1_functional.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 129, 690, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 129, 690, 32) 320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 129, 690, 32) 9248        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 43, 230, 32)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 43, 230, 32)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 43, 230, 64)  18496       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 22, 77, 64)   61504       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 25, 64)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 10, 25, 64)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 17, 25, 64)   0           max_pooling2d_10[0][0]           \n",
      "                                                                 average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 17, 25, 64)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 17, 25, 128)  73856       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 54400)        0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1024)         55706624    flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           10250       dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 55,880,298\n",
      "Trainable params: 55,880,298\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "visible = Input(shape=(129,690,1))\n",
    "\n",
    "conv1 = Conv2D(32, kernel_size=(3, 3), strides=(1,1), activation='relu', padding='same')(visible)\n",
    "\n",
    "conv2 = Conv2D(32, kernel_size=(3, 3), strides=(1,1), activation='relu', padding='same')(conv1)\n",
    "\n",
    "pool2 = MaxPooling2D(pool_size=(3, 3), strides=(3,3))(conv2)\n",
    "\n",
    "drop2 = Dropout(0.25)(pool2)\n",
    "\n",
    "conv3 = Conv2D(64, kernel_size=(3, 3), strides=(1,1), activation='relu', padding='same')(drop2)\n",
    "\n",
    "conv4 = Conv2D(64, kernel_size=(3, 5), strides=(2,3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "pool4 = MaxPooling2D(pool_size=(3, 3), strides=(3,3))(conv4)\n",
    "\n",
    "conv5 = Conv2D(64, kernel_size=(10, 3), strides=(3,3), activation='relu', padding='same')(pool4)\n",
    "\n",
    "pool5 = AveragePooling2D(pool_size=(3, 3), strides=(2,3))(conv4)\n",
    "\n",
    "mrg = Concatenate(axis=1)([pool4, pool5]) \n",
    "\n",
    "drop3 = Dropout(0.25)(mrg)\n",
    "\n",
    "conv6 = Conv2D(128, kernel_size=(3, 3), strides=(1,1), activation='relu', padding='same')(drop3)\n",
    "\n",
    "flat = Flatten()(conv6)\n",
    "\n",
    "fc = Dense(1024, activation='relu')(flat)\n",
    "\n",
    "output = Dense(10, activation='softmax')(fc)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "print( model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5279 samples, validate on 587 samples\n",
      "Epoch 1/20\n",
      "5279/5279 [==============================] - 26s 5ms/step - loss: 1.8360 - acc: 0.3493 - val_loss: 1.4189 - val_acc: 0.4906\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.41892, saving model to ./model/urban_sound2_functional.h5\n",
      "Epoch 2/20\n",
      "5279/5279 [==============================] - 24s 4ms/step - loss: 1.2549 - acc: 0.5618 - val_loss: 1.2188 - val_acc: 0.5724\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.41892 to 1.21881, saving model to ./model/urban_sound2_functional.h5\n",
      "Epoch 3/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.9818 - acc: 0.6653 - val_loss: 1.0338 - val_acc: 0.6508\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.21881 to 1.03381, saving model to ./model/urban_sound2_functional.h5\n",
      "Epoch 4/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.7483 - acc: 0.7420 - val_loss: 0.9099 - val_acc: 0.7189\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.03381 to 0.90986, saving model to ./model/urban_sound2_functional.h5\n",
      "Epoch 5/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.5240 - acc: 0.8244 - val_loss: 0.7440 - val_acc: 0.7922\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.90986 to 0.74404, saving model to ./model/urban_sound2_functional.h5\n",
      "Epoch 6/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.3985 - acc: 0.8653 - val_loss: 0.7919 - val_acc: 0.7785\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.74404\n",
      "Epoch 7/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.3342 - acc: 0.8844 - val_loss: 0.8419 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.74404\n",
      "Epoch 8/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.3272 - acc: 0.8932 - val_loss: 0.6673 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.74404 to 0.66726, saving model to ./model/urban_sound2_functional.h5\n",
      "Epoch 9/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.2279 - acc: 0.9273 - val_loss: 0.6542 - val_acc: 0.8365\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.66726 to 0.65420, saving model to ./model/urban_sound2_functional.h5\n",
      "Epoch 10/20\n",
      "5279/5279 [==============================] - 24s 5ms/step - loss: 0.1594 - acc: 0.9504 - val_loss: 0.8604 - val_acc: 0.7973\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.65420\n",
      "Epoch 11/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.1253 - acc: 0.9648 - val_loss: 0.8405 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.65420\n",
      "Epoch 12/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.1595 - acc: 0.9526 - val_loss: 0.9296 - val_acc: 0.8109\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.65420\n",
      "Epoch 13/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.1537 - acc: 0.9549 - val_loss: 0.7182 - val_acc: 0.8535\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.65420\n",
      "Epoch 14/20\n",
      "5279/5279 [==============================] - 23s 4ms/step - loss: 0.0932 - acc: 0.9720 - val_loss: 0.7868 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.65420\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe6c36af98>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "\n",
    "MODEL_SAVE_FOLDER_PATH = './model/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + 'urban_sound2_functional.h5'\n",
    "model_checkpoint = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping, model_checkpoint], verbose=1, validation_split=0.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467/1467 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7069239361845236, 0.8323108385676986]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model/urban_sound2_functional.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensor]",
   "language": "python",
   "name": "conda-env-tensor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
